{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O_datsZMfiV0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import zipfile\n",
        "import os\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-NBDYE1fvkj",
        "outputId": "27638958-df6f-45a0-e3c0-64526494af37"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1QwItNnETzlWHgZ89EbHFYg04ijkDszF6\n",
            "From (redirected): https://drive.google.com/uc?id=1QwItNnETzlWHgZ89EbHFYg04ijkDszF6&confirm=t&uuid=fbd116af-370c-499a-be01-55dffa6bda58\n",
            "To: /content/disease.zip\n",
            "100%|██████████| 3.85G/3.85G [00:55<00:00, 68.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Google Drive file URL\n",
        "file_url = \"https://drive.google.com/uc?id=1vHCvd9ZFkY9lfNwUnnMUbDQZjjpby8lv\"\n",
        "\n",
        "#Specify the output file path (the path where you want to save the file)\n",
        "output_file = \"disease.zip\"  # Replace with actual file name\n",
        "\n",
        "#Download the file\n",
        "gdown.download(file_url, output_file, quiet=False)\n",
        "\n",
        "zip_file = \"disease.zip\"  #Name of the downloaded file\n",
        "\n",
        "#Make sure output directory exists\n",
        "output_dir = \"/content/extracted_file\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "#Extract the contents\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncObBsB4fpIx",
        "outputId": "165645ce-7d5e-42ec-dcbc-d9841f31d946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 19436 images belonging to 2 classes.\n",
            "Found 2159 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 169ms/step - accuracy: 0.7664 - loss: 0.4750 - val_accuracy: 0.7925 - val_loss: 0.4053\n",
            "Epoch 2/10\n",
            "\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 145ms/step - accuracy: 0.8625 - loss: 0.3093 - val_accuracy: 0.8300 - val_loss: 0.3350\n",
            "Epoch 3/10\n",
            "\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 147ms/step - accuracy: 0.8891 - loss: 0.2572 - val_accuracy: 0.8703 - val_loss: 0.2778\n",
            "Epoch 4/10\n",
            "\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 147ms/step - accuracy: 0.9136 - loss: 0.2099 - val_accuracy: 0.8536 - val_loss: 0.3213\n",
            "Epoch 5/10\n",
            "\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 151ms/step - accuracy: 0.9298 - loss: 0.1699 - val_accuracy: 0.8277 - val_loss: 0.3769\n",
            "Epoch 6/10\n",
            "\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 150ms/step - accuracy: 0.9397 - loss: 0.1458 - val_accuracy: 0.8648 - val_loss: 0.3108\n",
            "Epoch 7/10\n",
            "\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 149ms/step - accuracy: 0.9513 - loss: 0.1229 - val_accuracy: 0.9301 - val_loss: 0.1671\n",
            "Epoch 8/10\n",
            "\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 150ms/step - accuracy: 0.9572 - loss: 0.1067 - val_accuracy: 0.8499 - val_loss: 0.3888\n",
            "Epoch 9/10\n",
            "\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 151ms/step - accuracy: 0.9628 - loss: 0.0945 - val_accuracy: 0.8573 - val_loss: 0.3943\n",
            "Epoch 10/10\n",
            "\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 149ms/step - accuracy: 0.9688 - loss: 0.0789 - val_accuracy: 0.8898 - val_loss: 0.2942\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a0ef2cb5450>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Path to main train folder that has many class folders\n",
        "data_dir = \"/content/extracted_file/Retinal Fundus Images - Copy/train\"\n",
        "\n",
        "#Specify the exact classes you want to include\n",
        "target_classes = ['Glaucoma', 'Normal_Fundus']\n",
        "\n",
        "#Image settings\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create generators with only selected classes\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    classes=target_classes,  #This filters folders\n",
        "    class_mode='sparse',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    classes=target_classes,  #This filters folders\n",
        "    class_mode='sparse',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "#Build ResNet50-based model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "#Fine-tune last 30 layers of ResNet50\n",
        "for layer in base_model.layers[:-45]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[-45:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "#Compile with smaller learning rate for fine-tuning\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-DZGZ5TJkiRc"
      },
      "outputs": [],
      "source": [
        "model.save(\"Glaucoma.keras\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
